# System Design

## Infrastructure


```mermaid
flowchart TB
    LB["Cloud Load Balancer"] --> API["API/WebSocket Gateway (Cloud Run)"]
    API --> Pods["Service Pods (Cloud Run / Auto-scaling)"]
    
    Pods -->|contains| Conv["Conversation Service"]
    Pods -->|contains| Auth["Auth / User Service"]
    Pods -->|contains| Message["Message Service"]
    Pods -->|contains| RTC["Notification Service"]
    
    Pods --> FS["Cloud Firestore"]
    Pods --> PS["Cloud Pub/Sub"]
    
    CF["Cloud Functions"] --> FS
    CF --> PS
    
    Pods -.-> GCS["Google Cloud Storage"]
    Pods -.-> Search["Firestore Search"]

```
### System bottlenecks & Solutions

| Bottleneck           | Solution                                  | Trade-off |
|----------------------|-------------------------------------------|--------|
| Cold starts | Cloud Run minimum instances + warm-up requests | Slight cost increase for consistent performance |
| WebSocket memory     | Connection limits + Cloud Run auto-scaling       | Stateful connections need session affinity   |
| Message delivery     | Cloud Pub/Sub + async processing         | Low |
| Document reads      | Firestore caching + efficient queries             | Low |
| Real-time updates   | Firestore real-time listeners + Pub/Sub fan-out  | Low    |

We use Cloud Run for backend services instead of Kubernetes to achieve true serverless scaling and cost optimization. This eliminates infrastructure management overhead while maintaining high performance.

To support high quality code, we choose TypeScript for both backend and frontend.
We use REST API for auth, user and conversation management, use WebSocket for real-time chat, so we can maintain optimal performance for different scenarios. We use Cloud Run with automatic scaling to handle both REST and WebSocket traffic efficiently.

### How to scale to 10K concurrent users

- Firestore automatically handles horizontal scaling without manual sharding or partitioning - queries scale seamlessly as document count grows.
- Cloud Run auto-scales instances based on demand, supporting thousands of concurrent WebSocket connections with automatic load balancing.
- Cloud Pub/Sub provides massive fan-out capability (millions of messages/second) for real-time message delivery.
- Use Firestore composite indexes and query optimization for efficient document retrieval at scale.
- Implement connection limits and API rate limiting via Cloud Endpoints or API Gateway to protect system resources.


### Database and Data Schema
We use Cloud Firestore as a serverless NoSQL document database that automatically scales and provides real-time updates. This eliminates the need for manual partitioning, connection pooling, and infrastructure management while reducing operational costs significantly.

```mermaid
graph TB
    subgraph "Firestore Collections"
        Users["ğŸ‘¤ users/"]
        Conversations["ğŸ’¬ conversations/"]
    end
    
    subgraph "User Document Structure"
        UserDoc["ğŸ“„ users/{email}<br/>â€¢ hashedPassword: string<br/>â€¢ displayName: string<br/>â€¢ avatarUrl?: string<br/>â€¢ isOnline: boolean<br/>â€¢ lastSeen: timestamp<br/>â€¢ createdAt: timestamp"]
    end
    
    subgraph "Conversation Document Structure"
        ConvDoc["ğŸ“„ conversations/{convId}<br/>â€¢ id: conv_{timestamp}_{random}<br/>â€¢ createdBy: email<br/>â€¢ type: DIRECT | GROUP<br/>â€¢ participantEmails: string[]<br/>â€¢ createdAt: timestamp<br/>â€¢ updatedAt: timestamp"]
    end
    
    subgraph "Subcollections"
        Participants["ğŸ‘¥ participants/{email}<br/>â€¢ userId: email<br/>â€¢ joinedAt: timestamp<br/>â€¢ role: ADMIN | MEMBER"]
        Messages["ğŸ“ messages/{msgId}<br/>â€¢ id: msg_{timestamp}_{random}<br/>â€¢ conversationId: string<br/>â€¢ senderId: email<br/>â€¢ senderDisplayName: string<br/>â€¢ messageType: TEXT | IMAGE | FILE<br/>â€¢ content: string<br/>â€¢ createdAt: timestamp<br/>â€¢ updatedAt: timestamp"]
        MessageStatus["ğŸ“Š status/{email}<br/>â€¢ userId: email<br/>â€¢ status: SENT | DELIVERED | READ | FAILED<br/>â€¢ sentAt: timestamp<br/>â€¢ deliveredAt?: timestamp<br/>â€¢ readAt?: timestamp"]
    end
    
    Users --> UserDoc
    Conversations --> ConvDoc
    ConvDoc --> Participants
    ConvDoc --> Messages
    Messages --> MessageStatus
```
### Backend
API Endpoints:
-   `POST /v1/auth/register`, register action, return user public info, no protected
    
-   `POST /v1/auth/login`, login action, return JWT token, no protected
    
-   `GET /v1/users/me`, user query api, protected
    
-   `GET /v1/conversations`, conversation collection query api, protected
    
-   `POST /v1/conversations`, new conversation api, protected
    
-   `GET /v1/conversations/:convId/messages`, message collection query api, protected
    
-   `POST /v1/conversations/:convId/messages`, new message api, protected
    
-   `GET /v1/conversations/:convId/messages/:msgId`, individual message query, protected
    
-   `PUT /v1/conversations/:convId/messages/:msgId`, update message api, protected
    
-   `DELETE /v1/conversations/:convId/messages/:msgId`, delete message api, protected
    
-   `WebSocket /ws` (for real-time updates), real-time message delivery, protected

**API Design Principles:**
- API naming: all APIs use `/v1/service/action`, `/v1/service/collection`, `/v1/service/collection/item` format
- All collection query APIs support pagination with `page` and `limit` parameters
- All protected APIs require JWT token for authentication - stateless design for serverless scaling
- All APIs use HTTP status codes for success/error cases and return structured error objects
- Use Firebase Admin SDK for Firestore operations and Cloud Pub/Sub for real-time messaging
- Conversation IDs: `conv_{timestamp}_{randomString}` format for better performance
- Message IDs: `msg_{timestamp}_{randomString}` format for chronological ordering

### Frontend
For frontend, we will use LWC(Lightning Web Components) so we can reuse existed components.

### Code structure
We use monorepo structure with shared packages.
```
chatflow/
â”œâ”€â”€ .github/                     # TODO: GitHub Actions CI/CD
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci.yml
â”‚       â”œâ”€â”€ deploy-staging.yml
â”‚       â””â”€â”€ deploy-production.yml
â”œâ”€â”€ .gitlab-ci.yml              # TODO: GitLab CI/CD (alternative)
â”œâ”€â”€ docker/                     # Docker configurations
â”‚   â”œâ”€â”€ nginx/ # TODO:
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ nginx.conf
â”‚   â”‚   â””â”€â”€ nginx.dev.conf
â”‚   â””â”€â”€ postgres/
â”‚       â””â”€â”€ Dockerfile
â”œâ”€â”€ k8s/                        # TODO: Kubernetes manifests
â”‚   â”œâ”€â”€ base/
â”‚   â”‚   â”œâ”€â”€ namespace.yaml
â”‚   â”‚   â”œâ”€â”€ configmap.yaml
â”‚   â”‚   â”œâ”€â”€ secrets.yaml
â”‚   â”‚   â”œâ”€â”€ postgres.yaml
â”‚   â”‚   â”œâ”€â”€ redis.yaml
â”‚   â”‚   â”œâ”€â”€ backend.yaml
â”‚   â”‚   â”œâ”€â”€ frontend.yaml
â”‚   â”‚   â””â”€â”€ nginx.yaml
â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â”œâ”€â”€ kustomization.yaml
â”‚   â”‚   â””â”€â”€ ingress.yaml
â”‚   â””â”€â”€ production/
â”‚       â”œâ”€â”€ kustomization.yaml
â”‚       â”œâ”€â”€ ingress.yaml
â”‚       â””â”€â”€ hpa.yaml
â”œâ”€â”€ scripts/                    # TODO: Utility scripts
â”‚   â”œâ”€â”€ setup.sh
â”‚   â”œâ”€â”€ build.sh
â”‚   â”œâ”€â”€ deploy.sh
â”‚   â””â”€â”€ migrate.sh
â”œâ”€â”€ shared/      # shared code
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tsconfig.json
â”œâ”€â”€ prisma/      # DB schema
â”‚   â””â”€â”€ migrations/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tsconfig.json
â””â”€â”€ frontend/   # simple frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tsconfig.json
â”œâ”€â”€ docker-compose.yml          # Development environment
â”œâ”€â”€ docker-compose.prod.yml     # Production environment
â”œâ”€â”€ package.json                # Root package.json
â”œâ”€â”€ tsconfig.json              # Root TypeScript config
â”œâ”€â”€ .env.example               # Environment variables template
â””â”€â”€ README.md

```